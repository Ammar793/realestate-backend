name: Deploy Lambda Functions

on:
  push:
    branches: [ "main" ]
  workflow_dispatch: {}

permissions:
  id-token: write   # for AWS OIDC
  contents: read

concurrency:
  group: deploy-lambda
  cancel-in-progress: true

jobs:
  deploy:
    runs-on: ubuntu-latest
    environment: main

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"  # Using 3.11 for better compatibility with C++ packages like strands
          cache: "pip"

      - name: Build main lambda deployment zip
        run: |
          set -euo pipefail
          rm -rf build-main function-main.zip
          mkdir -p build-main

          # Install dependencies with size optimization
          python -m pip install --upgrade pip
          if [ -f main-lambda/requirements.txt ] && [ -s main-lambda/requirements.txt ]; then
            pip install -r main-lambda/requirements.txt --target build-main --no-deps --compile
          fi

          # Add main lambda code
          cp main-lambda/lambda_function.py build-main/
          cp shared/strands_orchestrator.py build-main/
          
          # Clean up unnecessary files to reduce package size
          find build-main -name "*.pyc" -delete
          find build-main -name "__pycache__" -type d -exec rm -rf {} + 2>/dev/null || true
          find build-main -name "*.dist-info" -type d -exec rm -rf {} + 2>/dev/null || true
          find build-main -name "tests" -type d -exec rm -rf {} + 2>/dev/null || true
          find build-main -name "*.txt" -delete
          find build-main -name "*.md" -delete

          # Zip everything
          (cd build-main && zip -r ../function-main.zip .)
          
          # Check package size
          PACKAGE_SIZE=$(du -m ../function-main.zip | cut -f1)
          echo "Main lambda package size: ${PACKAGE_SIZE}MB"
          
          # Fail if package is too large (Lambda limit is ~50MB)
          if [ "$PACKAGE_SIZE" -gt 45 ]; then
            echo "ERROR: Package size ${PACKAGE_SIZE}MB exceeds Lambda limit of 50MB"
            exit 1
          fi

      - name: Build tool lambda deployment zip
        run: |
          set -euo pipefail
          rm -rf build-tool function-tool.zip
          mkdir -p build-tool

          # Install dependencies with size optimization
          python -m pip install --upgrade pip
          if [ -f tool-lambda/requirements.txt ] && [ -s tool-lambda/requirements.txt ]; then
            pip install -r tool-lambda/requirements.txt --target build-tool --no-deps --compile
          fi

          # Add tool lambda code
          cp tool-lambda/tool_lambda_function.py build-tool/
          cp shared/strands_orchestrator.py build-tool/
          
          # Clean up unnecessary files to reduce package size
          find build-tool -name "*.pyc" -delete
          find build-tool -name "__pycache__" -type d -exec rm -rf {} + 2>/dev/null || true
          find build-tool -name "*.dist-info" -type d -exec rm -rf {} + 2>/dev/null || true
          find build-tool -name "tests" -type d -exec rm -rf {} + 2>/dev/null || true
          find build-tool -name "*.txt" -delete
          find build-tool -name "*.md" -delete

          # Zip everything
          (cd build-tool && zip -r ../function-tool.zip .)
          
          # Check package size
          PACKAGE_SIZE=$(du -m ../function-tool.zip | cut -f1)
          echo "Tool lambda package size: ${PACKAGE_SIZE}MB"
          
          # Fail if package is too large (Lambda limit is ~50MB)
          if [ "$PACKAGE_SIZE" -gt 45 ]; then
            echo "ERROR: Package size ${PACKAGE_SIZE}MB exceeds Lambda limit of 50MB"
            exit 1
          fi

      - name: Configure AWS credentials (OIDC)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::642466639437:role/github_role
          aws-region: us-west-2

      - name: Update main lambda code
        run: |
          aws lambda update-function-code \
            --function-name selador-realestate-backend \
            --zip-file fileb://function-main.zip \
            --publish
          aws lambda wait function-updated --function-name selador-realestate-backend

      - name: Create env JSON for main lambda
        run: |
          cat > env-main.json <<'EOF'
          {
            "Variables": {
              "KNOWLEDGE_BASE_ID": "${{ vars.KNOWLEDGE_BASE_ID }}",
              "MODEL_ARN": "${{ vars.MODEL_ARN }}",
              "GATEWAY_NAME": "${{ vars.GATEWAY_NAME || 'JLSRealEstateGateway' }}",
              "AGENTCORE_GATEWAY_URL": "${{ vars.AGENTCORE_GATEWAY_URL }}",
              "AGENTCORE_ACCESS_TOKEN": "${{ secrets.AGENTCORE_ACCESS_TOKEN }}",
              "AGENT_LOG_LEVEL": "INFO",
              "AGENT_TIMEOUT": "30",
              "AGENT_MAX_RETRIES": "3",
              "WORKFLOW_PARALLEL_LIMIT": "5",
              "WORKFLOW_TIMEOUT": "120",
              "API_RATE_LIMIT": "100",
              "API_TIMEOUT": "30",
              "LOG_LEVEL": "INFO",
              "LOG_FORMAT": "json",
              "LOG_DESTINATION": "cloudwatch"
            }
          }
          EOF

      - name: Update main lambda environment variables
        run: |
          aws lambda update-function-configuration \
            --function-name selador-realestate-backend \
            --environment file://env-main.json

      - name: Create env JSON for tool lambda
        run: |
          cat > env-tool.json <<'EOF'
          {
            "Variables": {
              "KNOWLEDGE_BASE_ID": "${{ vars.KNOWLEDGE_BASE_ID }}",
              "MODEL_ARN": "${{ vars.MODEL_ARN }}",
              "GATEWAY_NAME": "${{ vars.GATEWAY_NAME || 'JLSRealEstateGateway' }}",
              "AGENTCORE_GATEWAY_URL": "${{ vars.AGENTCORE_GATEWAY_URL }}",
              "AGENTCORE_ACCESS_TOKEN": "${{ secrets.AGENTCORE_ACCESS_TOKEN }}",
              "AGENT_LOG_LEVEL": "${{ vars.AGENT_LOG_LEVEL || 'INFO' }}",
              "AGENT_TIMEOUT": "${{ vars.AGENT_TIMEOUT || '30' }}",
              "AGENT_MAX_RETRIES": "${{ vars.AGENT_MAX_RETRIES || '3' }}",
              "WORKFLOW_PARALLEL_LIMIT": "${{ vars.WORKFLOW_PARALLEL_LIMIT || '5' }}",
              "WORKFLOW_TIMEOUT": "${{ vars.WORKFLOW_TIMEOUT || '120' }}",
              "API_RATE_LIMIT": "${{ vars.API_RATE_LIMIT || '100' }}",
              "API_TIMEOUT": "${{ vars.API_TIMEOUT || '30' }}",
              "LOG_LEVEL": "${{ vars.LOG_LEVEL || 'INFO' }}",
              "LOG_FORMAT": "${{ vars.LOG_FORMAT || 'json' }}",
              "LOG_DESTINATION": "${{ vars.LOG_DESTINATION || 'cloudwatch' }}"
            }
          }
          EOF

      - name: Update tool lambda environment variables
        run: |
          aws lambda update-function-configuration \
            --function-name selador-realestate-tools \
            --environment file://env-tool.json

      # ----- Optional: use S3 if your zip ever exceeds 50MB -----
      # - name: Upload zips to S3
      #   run: |
      #     aws s3 cp function-main.zip s3://<your-artifacts-bucket>/lambda/main-function.zip
      #     aws s3 cp function-tool.zip s3://<your-artifacts-bucket>/lambda/tool-function.zip
      #
      # - name: Update Lambda code (from S3)
      #   run: |
      #     aws lambda update-function-code \
      #       --function-name selador-realestate-backend \
      #       --s3-bucket <your-artifacts-bucket> \
      #       --s3-key lambda/main-function.zip \
      #       --publish
      #     aws lambda wait function-updated --function-name selador-realestate-backend
      #     
      #     aws lambda update-function-code \
      #       --function-name selador-realestate-tools \
      #       --s3-bucket <your-artifacts-bucket> \
      #       --s3-key lambda/tool-function.zip \
      #       --publish
      #     aws lambda wait function-updated --function-name selador-realestate-tools
