name: Deploy Lambda Functions

on:
  push:
    branches: [ "main" ]
  workflow_dispatch: {}

permissions:
  id-token: write   # for AWS OIDC
  contents: read

concurrency:
  group: deploy-lambda
  cancel-in-progress: true

jobs:
  deploy:
    runs-on: ubuntu-latest
    environment: main

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"  # Using 3.11 for better compatibility with C++ packages like strands
          cache: "pip"

      - name: Build main lambda deployment zip
        run: |
          set -euo pipefail
          rm -rf build-main function-main.zip
          mkdir -p build-main

          # Install dependencies
          python -m pip install --upgrade pip
          echo "Installing dependencies from main-lambda/requirements.txt..."
          echo "Requirements file contents:"
          cat main-lambda/requirements.txt || echo "No requirements.txt found"
          
          if [ -f main-lambda/requirements.txt ] && [ -s main-lambda/requirements.txt ]; then
            echo "Starting pip install..."
            pip install -r main-lambda/requirements.txt --target build-main --verbose
            echo "Dependencies installed successfully"
            
            # Show what was installed
            echo "Installed packages in build-main:"
            ls -la build-main/ || echo "build-main directory not found"
          else
            echo "No requirements.txt found or file is empty"
          fi

          # Add main lambda code
          cp main-lambda/lambda_function.py build-main/
          # Copy all shared modules
          cp -r shared/* build-main/
          
          # Debug: Show what's in the build directory
          echo "Contents of build-main directory:"
          ls -la build-main/
          
          # Check if directory has content
          if [ -z "$(ls -A build-main)" ]; then
            echo "ERROR: build-main directory is empty!"
            exit 1
          fi

          # Show final contents before zipping
          echo "Final contents before zipping:"
          ls -la build-main/
          
          # Check if zip command is available
          if ! command -v zip &> /dev/null; then
            echo "ERROR: zip command not found. Installing zip..."
            apt-get update && apt-get install -y zip
          fi
          
          # Zip everything with verbose output
          echo "Creating zip file..."
          cd build-main
          zip -r ../function-main.zip . -v
          cd ..
          
          # Verify zip was created
          if [ ! -f function-main.zip ]; then
            echo "ERROR: Failed to create function-main.zip"
            echo "Current directory contents:"
            ls -la
            exit 1
          fi
          
          # Check package size (informational only - S3 handles large packages)
          PACKAGE_SIZE=$(du -m function-main.zip | cut -f1)
          echo "Main lambda package size: ${PACKAGE_SIZE}MB"

      - name: Build tool lambda deployment zip
        run: |
          set -euo pipefail
          rm -rf build-tool function-tool.zip
          mkdir -p build-tool

          # Install dependencies
          python -m pip install --upgrade pip
          echo "Installing dependencies from tool-lambda/requirements.txt..."
          echo "Requirements file contents:"
          cat tool-lambda/requirements.txt || echo "No requirements.txt found"
          
          if [ -f tool-lambda/requirements.txt ] && [ -s tool-lambda/requirements.txt ]; then
            echo "Starting pip install..."
            pip install -r tool-lambda/requirements.txt --target build-tool --verbose
            echo "Dependencies installed successfully"
            
            # Show what was installed
            echo "Installed packages in build-tool:"
            ls -la build-tool/ || echo "build-tool directory not found"
          else
            echo "No requirements.txt found or file is empty"
          fi

          # Add tool lambda code
          cp tool-lambda/tool_lambda_function.py build-tool/
          # Copy all shared modules
          cp -r shared/* build-tool/
          
          # Debug: Show what's in the build directory
          echo "Contents of build-tool directory:"
          ls -la build-tool/
          
          # Check if directory has content
          if [ -z "$(ls -A build-tool)" ]; then
            echo "ERROR: build-tool directory is empty!"
            exit 1
          fi


          # Show final contents before zipping
          echo "Final contents before zipping:"
          ls -la build-tool/
          
          # Check if zip command is available
          if ! command -v zip &> /dev/null; then
            echo "ERROR: zip command not found. Installing zip..."
            apt-get update && apt-get install -y zip
          fi
          
          # Zip everything with verbose output
          echo "Creating zip file..."
          cd build-tool
          zip -r ../function-tool.zip . -v
          cd ..
          
          # Verify zip was created
          if [ ! -f function-tool.zip ]; then
            echo "ERROR: Failed to create function-tool.zip"
            echo "Current directory contents:"
            ls -la
            exit 1
          fi
          
          # Check package size (informational only - S3 handles large packages)
          PACKAGE_SIZE=$(du -m function-tool.zip | cut -f1)
          echo "Tool lambda package size: ${PACKAGE_SIZE}MB"

      - name: Configure AWS credentials (OIDC)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::642466639437:role/github_role
          aws-region: us-west-2

      # Note: Lambda code is now updated from S3 in the step below

      - name: Create env JSON for main lambda
        run: |
          cat > env-main.json <<'EOF'
          {
            "Variables": {
              "KNOWLEDGE_BASE_ID": "${{ vars.KNOWLEDGE_BASE_ID }}",
              "MODEL_ARN": "${{ vars.MODEL_ARN }}",
              "GATEWAY_NAME": "${{ vars.GATEWAY_NAME || 'JLSRealEstateGateway' }}",
              "AGENTCORE_GATEWAY_URL": "${{ vars.AGENTCORE_GATEWAY_URL }}",
              "AGENTCORE_ACCESS_TOKEN": "${{ secrets.AGENTCORE_ACCESS_TOKEN }}",
              "COGNITO_CLIENT_ID": "${{ vars.COGNITO_CLIENT_ID }}",
              "COGNITO_CLIENT_SECRET": "${{ secrets.COGNITO_CLIENT_SECRET }}",
              "COGNITO_TOKEN_URL": "${{ vars.COGNITO_TOKEN_URL }}",
              "COGNITO_USER_POOL_ID": "${{ vars.COGNITO_USER_POOL_ID }}",
              "COGNITO_IDENTITY_POOL_ID": "${{ vars.COGNITO_IDENTITY_POOL_ID }}",
              "AGENT_LOG_LEVEL": "INFO",
              "AGENT_TIMEOUT": "30",
              "AGENT_MAX_RETRIES": "3",
              "WORKFLOW_PARALLEL_LIMIT": "5",
              "WORKFLOW_TIMEOUT": "120",
              "API_RATE_LIMIT": "100",
              "API_TIMEOUT": "30",
              "LOG_LEVEL": "INFO",
              "LOG_FORMAT": "json",
              "LOG_DESTINATION": "cloudwatch",
              "OTEL_PYTHON_DISABLED": "true",
              "STRANDS_DISABLE_TELEMETRY": "true"
            }
          }
          EOF

      - name: Update main lambda environment variables
        run: |
          aws lambda update-function-configuration \
            --function-name selador-realestate-backend \
            --environment file://env-main.json \
            --layers arn:aws:lambda:us-west-2:184161586896:layer:opentelemetry-python-0_15_0:1


      - name: Create env JSON for tool lambda
        run: |
          cat > env-tool.json <<'EOF'
          {
            "Variables": {
              "KNOWLEDGE_BASE_ID": "${{ vars.KNOWLEDGE_BASE_ID }}",
              "MODEL_ARN": "${{ vars.MODEL_ARN }}",
              "GATEWAY_NAME": "${{ vars.GATEWAY_NAME || 'JLSRealEstateGateway' }}",
              "AGENTCORE_GATEWAY_URL": "${{ vars.AGENTCORE_GATEWAY_URL }}",
              "AGENTCORE_ACCESS_TOKEN": "${{ secrets.AGENTCORE_ACCESS_TOKEN }}",
              "COGNITO_CLIENT_ID": "${{ vars.COGNITO_CLIENT_ID }}",
              "COGNITO_CLIENT_SECRET": "${{ secrets.COGNITO_CLIENT_SECRET }}",
              "COGNITO_TOKEN_URL": "${{ vars.COGNITO_TOKEN_URL }}",
              "COGNITO_USER_POOL_ID": "${{ vars.COGNITO_USER_POOL_ID }}",
              "COGNITO_IDENTITY_POOL_ID": "${{ vars.COGNITO_IDENTITY_POOL_ID }}",
              "AGENT_LOG_LEVEL": "${{ vars.AGENT_LOG_LEVEL || 'INFO' }}",
              "AGENT_TIMEOUT": "${{ vars.AGENT_TIMEOUT || '30' }}",
              "AGENT_MAX_RETRIES": "${{ vars.AGENT_MAX_RETRIES || '3' }}",
              "WORKFLOW_PARALLEL_LIMIT": "${{ vars.WORKFLOW_PARALLEL_LIMIT || '5' }}",
              "WORKFLOW_TIMEOUT": "${{ vars.WORKFLOW_TIMEOUT || '120' }}",
              "API_RATE_LIMIT": "${{ vars.API_RATE_LIMIT || '100' }}",
              "API_TIMEOUT": "${{ vars.API_TIMEOUT || '30' }}",
              "LOG_LEVEL": "${{ vars.LOG_LEVEL || 'INFO' }}",
              "LOG_FORMAT": "${{ vars.LOG_FORMAT || 'json' }}",
              "LOG_DESTINATION": "${{ vars.LOG_DESTINATION || 'cloudwatch' }}",
              "OTEL_PYTHON_DISABLED": "true",
              "STRANDS_DISABLE_TELEMETRY": "true"
            }
          }
          EOF

      - name: Update tool lambda environment variables
        run: |
          aws lambda update-function-configuration \
            --function-name selador-realestate-tools \
            --environment file://env-tool.json \
            --layers arn:aws:lambda:us-west-2:184161586896:layer:opentelemetry-python-0_15_0:1

      # ----- S3 upload for large packages (recommended approach) -----
      - name: Upload zips to S3
        run: |
          # Create S3 bucket if it doesn't exist
          aws s3 mb s3://jls-lambda-artifacts --region us-west-2 || true
          
          # Clean up old artifacts (keep last 5 versions)
          aws s3 ls s3://jls-lambda-artifacts/lambda/ | grep "main-function" | sort -r | tail -n +6 | awk '{print $4}' | xargs -I {} aws s3 rm s3://jls-lambda-artifacts/lambda/{} || true
          aws s3 ls s3://jls-lambda-artifacts/lambda/ | grep "tool-function" | sort -r | tail -n +6 | awk '{print $4}' | xargs -I {} aws s3 rm s3://jls-lambda-artifacts/lambda/{} || true
          
          # Upload deployment packages with timestamp
          TIMESTAMP=$(date +%Y%m%d-%H%M%S)
          aws s3 cp function-main.zip s3://jls-lambda-artifacts/lambda/main-function-${TIMESTAMP}.zip
          aws s3 cp function-tool.zip s3://jls-lambda-artifacts/lambda/tool-function-${TIMESTAMP}.zip
          
          # Also upload as latest versions
          aws s3 cp function-main.zip s3://jls-lambda-artifacts/lambda/main-function.zip
          aws s3 cp function-tool.zip s3://jls-lambda-artifacts/lambda/tool-function.zip
          
          echo "Packages uploaded to S3 successfully with timestamp: ${TIMESTAMP}"

      - name: Update Lambda code (from S3)
        run: |
          # Update main lambda from S3
          aws lambda update-function-code \
            --function-name selador-realestate-backend \
            --s3-bucket jls-lambda-artifacts \
            --s3-key lambda/main-function.zip \
            --publish
          aws lambda wait function-updated --function-name selador-realestate-backend
          
          # Update tool lambda from S3
          aws lambda update-function-code \
            --function-name selador-realestate-tools \
            --s3-bucket jls-lambda-artifacts \
            --s3-key lambda/tool-function.zip \
            --publish
          aws lambda wait function-updated --function-name selador-realestate-tools
